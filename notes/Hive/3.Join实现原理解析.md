Hive中的join分为两种情况：

* Common Join（Reduce阶段完成join）

* Map Join（Map阶段完成join）

如果没开启hive.auto.convert.join=true或者不符合MapJoin的条件，那么Hive解析器会将Join操作转换成Common Join,在Reduce阶段完成join。并且整个过程包含Map、Shuffle、Reduce阶段。

1、Common Join/Reduce Join

1.1 map阶段

map输出key：以join的关联键作为key。如果join有多个关联列，则以这些关联键的组合作为key。

map输出value： 为 join 之后需要输出或者作为条件的列；同时在value中还会包含表的 Tag 信息，用于标明此value对应的表；按照key进行排序。

![jion](../assets/jion.png)



map端的主要工作：为来自不同表(文件)的 key/value 对打标签以区别不同来源的记录。然后用连接字段作为 key，其余部分和新加的标志作为 value，最后进行输出。

1.2 shuffle阶段

根据key的值进行hash,并将key/value按照hash值推送至不同的reduce中，这样确保两个表中相同的key位于同一个reduce中。

1.3 reduce阶段

根据key的值完成join操作，并且通过Tag来识别不同表中的数据。在合并过程中，把表编号扔掉。

reduce端的主要工作：在 reduce 端以连接字段作为 key 的分组已经完成，我们只需要在每一个分组当中将那些来源于不同文件的记录(在 map 阶段已经打标志)分开，最后进行合并就 ok 了。

1.4 案例join运行过程分析

```sql
-- 1.学生信息表(user_info)
+----------+------------+--+
| user_id  | user_name  |
+----------+------------+--+
| 1        | 小红         |
| 2        | 小明         |
| 3        | 小花         |
+----------+------------+--+
-- 2.学生选课表(curse_info)
 +----------+--------------+--+
| user_id  | course_name  |
+----------+--------------+--+
| 1        | spark        |
| 2        | flink        |
| 3        | java         |
+----------+--------------+--+
```

需求：通过两张表关联，得到学生对应的课程名称。

```sql
select
     t1.user_id
    ,t1.user_name
    ,t2.course_name
from dwd.user_info t1
join dwd.curse_info t2
on t1.user_id = t2.user_id;
+----------+------------+--------------+--+
| user_id  | user_name  | course_name  |
+----------+------------+--------------+--+
| 1        | 小红         | spark        |
| 2        | 小明         | flink        |
| 3        | 小花         | java         |
+----------+------------+--------------+--+
```

图解：(在合并过程中，把表编号-a,b扔掉)

在map的输出value中为不同表的数据打上tag标记，在reduce阶段根据tag判断数据来源。

![img](../assets/3b312fbf-ea3d-4dc5-87ba-e561cd215098.png)

1.5 mapreduce实现hive join操作

```java
// zhihushxian
public static class JoinReducer extends
            Reducer<Text, Text, Text, NullWritable> {
        protected void reduce(Text key, Iterable<Text> values,
                              Context context) throws IOException, InterruptedException{
            List<String[]> lista = new ArrayList<String[]>();
            List<String[]> listb = new ArrayList<String[]>();

            for(Text val:values) {
                String[] str = val.toString().split(" ");
                // 最后一位是标签位，因此根据最后一位判断数据来自哪个文件
                // 标签为a的数据放在lista中，标签为b的数据放在listb中
                String flag = str[str.length -1];
                if("a".equals(flag)) {
                    //String valueA = str[0] + " " + str[1] + " " + str[2];
                    lista.add(str);
                } else if("b".equals(flag)) {
                    //String valueB = str[0] + " " + str[1];
                    listb.add(str);
                }
            }

            for (int i = 0; i < lista.size(); i++) {
                if (listb.size() == 0) {
                    continue;
                } else {
                    String[] stra = lista.get(i);
                    for (int j = 0; j < listb.size(); j++) {
                        String[] strb = listb.get(j);
                        String keyValue = stra[0] + " " + stra[1] + " " + stra[2] + " " + stra[3] + " " + strb[1];
                        context.write(new Text(keyValue), NullWritable.get());
                    }
                }
            }
        }
}
```



2、map join

MapJoin通常用于一个很小的表和一个大表进行join的场景，具体小表有多小，由参数**hive.mapjoin.smalltable.filesize**来决定，该参数表示小表的总大小，默认值为25000000字节，即25M。

Hive0.7之前，需要使用hint提示 /*+ mapjoin(table) */才会执行MapJoin,否则执行Common Join，但在0.7版本之后，默认自动会转换Map Join，由参数**hive.auto.convert.join**来控制，默认为true。

仍然以9.1中的HQL来说吧，假设a表为一张大表，b为小表，并且hive.auto.convert.join=true,那么Hive在执行时候会自动转化为MapJoin。

![Hive MapJoin](../assets/0625-3.jpg)



* 如图中的流程，首先是Task A，它是一个Local Task（在客户端本地【Driver】执行的Task），负责扫描小表b的数据，将其转换成一个HashTable的数据结构，并写入本地的文件中，之后将该文件加载到DistributeCache中，该HashTable的数据结构可以抽象为：

| key  | value |
| :--: | :---: |
|  1   |  26   |
|  2   |  34   |

![MapReduce Local Task](../assets/0625-2.jpg)

图中红框圈出了执行Local Task的信息。

- 接下来是Task B，该任务是一个没有Reduce的MR，启动MapTasks扫描大表a,在Map阶段，根据a的每一条记录去和DistributeCache中b表对应的HashTable关联，并直接输出结果。
- 由于MapJoin没有Reduce，所以由Map直接输出结果文件，有多少个Map Task，就有多少个结果文件。



参考链接：

[Hive的join底层mapreduce是如何实现的?](https://my.oschina.net/u/4631230/blog/4641969)

[Reduce join](https://www.kancloud.cn/king_om/h_001/2098058)

[一起学Hadoop——实现两张表之间的连接操作](https://zhuanlan.zhihu.com/p/45146226)

[Hive 优化](https://rabbitai.cn/article/detail/59/)

[Hive – Group By 的实现](http://fatkun.com/2013/01/hive-group-by.html)