## Distinct实现原理

### 1.Distinct一个字段

```sql
select 
	count
	, count(distinct uid) 
from logs 
group by count;
```

当只有一个distinct字段时，如果不考虑Map阶段的Hash GroupBy，只需要将GroupBy字段和Distinct字段组合为map输出key，利用mapreduce的排序，同时将GroupBy字段作为reduce的key，在reduce阶段保存LastKey即可完成去重。

![hive-distinct-cal](../assets/hive-distinct-cal.jpg)

* 1.在map阶段先进行预聚合操作，会以count和uid作为key输出；
* 2.虽然key是count和uid，但是在reduce时分区是按group by的字段count来的；
* 3.我们在第1步预计算的其只是去除重复的数据，减少发送到reduce端相同的数据量。第1步计算的结果并不准确，最终要以reduce计算的结果为准。而如果是count(uid)，那么，在reduce阶段就可以将预计算的结果合并起来。
* 4.distinct通过比较lastInvoke判断要不要+1（因为在reduce是排序过了的，所以判断distict的字段变了没有，如果没变，则不+1）

最后一步：

```sql
-- 假设reduce端的数据是这样的
<3, a>
<3, a>
<3, b>
<3, c>
```

那么，计算count(distinct uid)的时候，只需要比较<key1, key2>中的last_key也就是key2，因为利用mapreduce框架在reduce端排序的功能，key2是已经排好序了的。所以，只需要依次遍历，如果当前值与下一个值不一样，则+1，否则，不变。

### 2.Distinct多个字段

```sql
select 
	dealid
	, count(distinct uid)
	, count(distinct date) 
from order 
group by dealid;
```

实现方式有两种：

（1）和distinct一个字段方式

如果仍然按照上面一个distinct字段的方法，即下图这种实现方式，无法跟据uid和date分别排序，也就无法通过LastKey去重，仍然需要在reduce阶段在内存中通过Hash去重。

![image-20210609230415921](../assets/image-20210609230415921.png)

这是因为，无法利用mapreduce框架在reduce端排序的功能，将我们需要去重的多个字段都进行排序。所以，就没办法根据字段是否改变来计数。

如上图所示，distint uid和distinct dealid，这两个字段，没有办法分别排序，所以无法直接通过LastKey去重.

（2）第二种实现方式

可以对所有的distinct字段编号，每行数据生成n行数据，那么相同字段就会分别排序，这时只需要在reduce阶段记录LastKey即可去重。

![image-20210609230356078](../assets/image-20210609230356078.png)

如上图所示，有多少个distinct则对应多少行数据。

这种实现方式很好的利用了MapReduce的排序，节省了reduce阶段去重的内存消耗，但是缺点是增加了shuffle的数据量。

需要注意的是，在生成reduce value时，除第一个distinct字段所在行需要保留value值，其余distinct数据行value字段均可为空。

