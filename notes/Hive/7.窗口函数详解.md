## Hive 窗口与分析型函数

SQL 结构化查询语言是数据分析领域的重要工具之一。它提供了数据筛选、转换、聚合等操作，并能借助 Hive 和 Hadoop 进行大数据量的处理。但是，传统的 SQL 语句并不能支持诸如分组排名、滑动平均值等计算，原因是 `GROUP BY` 语句只能为每个分组的数据返回一行结果，而非每条数据一行。幸运的是，新版的 SQL 标准引入了窗口查询功能，使用 `WINDOW` 语句我们可以基于分区和窗口为每条数据都生成一行结果记录，这一标准也已得到了 Hive 的支持。

### 1.Group By与窗口函数对比

![image-20210610122645985](../assets/image-20210610122645985.png)

如上图所示，左图展示的是group by，右图展示的是窗口函数。

明显的不同是：

* group by：一个分组返回一行结果；
* 窗口函数：类似于递归的group by，可以基于分区和窗口为每条数据都生成一行结果记录。

窗口函数的功能要更加强大。

窗口函数和group by语法：

> 需求：计算每个部门的总工资。

（1）group by

```sql
SELECT 
    department_id,
    sum(salary) AS salary
FROM employee_table
GROUP BY 
	department_id
DEPARTMENT_ID TOTAL_SALARY
------------- 结果 ------------
部门id 		  总工资
100        		51608
30        		24900
21           	7000
20        		19000
70        		10000
90        		58000
110        		20308
50       		156400
40         		6500
80       		304500
10         		4400
60        		28800
```

（2）使用窗口函数实现计算每个部门的总工资

```sql
SELECT
DISTINCT department_id,
SUM(salary) OVER (PARTITION BY department_id) AS salary
FROM employee_table

------------- 结果 ------------
部门id 		  总工资
30        		24900
60        		28800
90        		58000
10         		4400
100        		51608
20        		19000
50       		156400
40         		6500
80       		304500
70        		10000
110        		20308
```



### 2.窗口查询的基本概念

![Concepts](../assets/concepts.png)

#### 2.1 窗口函数语法

在窗口函数中，我们可以使用函数（例如*COUNT,* SUM等聚合函数），以及*PARTITION BY*, *ORDER BY* and *ROWS*等语句。其中*PARTITION BY* and *ROWS* elements are 可选的。

```sql
function (expression) OVER
     ( [ PARTITION BY expression_list ]
       [ ORDER BY order_list ]
       [ ROWS frame_clause ])
```

参数说明：

* `function`：定义计算方式；
* `OVER `：该参数是必须的；
* PARTITION BY `：将结果集划分到不同的分区；
* `ORDER BY `：为每个分区内的数据进行排序；
* `ROWS `：定义行偏移量。

例子，使用窗口函数计算日期、当天收益以及三日内平均收益。

```sql
select
	day
	,revenue
	,avg(revenue) over(order by day rows 2 preceding) as 3_day_revenue_avg	
from logs
```

计算结果如下图所示：

![image-20210610134947467](../assets/image-20210610134947467.png)

图中绿色单元格的计算结果，是红色框中的三条数据的平均值。

#### 2.2 窗口函数概念

![Concepts](../assets/concepts.png)

SQL 窗口查询引入了三个新的概念：窗口分区、窗口帧、以及窗口函数。

`PARTITION` 语句会按照一个或多个指定字段，将查询结果集拆分到不同的 **窗口分区** 中，并可按照一定规则排序。如果没有 `PARTITION BY`，则整个结果集将作为单个窗口分区；如果没有 `ORDER BY`，我们则无法定义窗口帧，进而整个分区将作为单个窗口帧进行处理。

**窗口帧** 用于从分区中选择指定的多条记录，供窗口函数处理。Hive 提供了两种定义窗口帧的形式：`ROWS` 和 `RANGE`。两种类型都需要配置上界和下界。例如，`ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW` 表示选择分区起始记录到当前记录的所有行；`SUM(close) RANGE BETWEEN 100 PRECEDING AND 200 FOLLOWING` 则通过 *字段差值* 来进行选择。如当前行的 `close` 字段值是 `200`，那么这个窗口帧的定义就会选择分区中 `close` 字段值落在 `100` 至 `400` 区间的记录。以下是所有可能的窗口帧定义组合。如果没有定义窗口帧，则默认为 `RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW`。

```sql
(ROWS | RANGE) BETWEEN (UNBOUNDED | [num]) PRECEDING AND ([num] PRECEDING | CURRENT ROW | (UNBOUNDED | [num]) FOLLOWING)
(ROWS | RANGE) BETWEEN CURRENT ROW AND (CURRENT ROW | (UNBOUNDED | [num]) FOLLOWING)
(ROWS | RANGE) BETWEEN [num] FOLLOWING AND (UNBOUNDED | [num]) FOLLOWING
```

**窗口函数** 会基于当前窗口帧的记录计算结果。Hive 提供了以下窗口函数：

![image-20210610135314353](../assets/image-20210610135314353.png)

部分函数功能说明：

- `FIRST_VALUE(col)`, `LAST_VALUE(col)` 可以返回窗口帧中第一条或最后一条记录的指定字段值；
- `LEAD(col, n)`, `LAG(col, n)` 返回当前记录的上 `n` 条或下 `n` 条记录的字段值；
- `RANK()`, `ROW_NUMBER()` 会为帧内的每一行返回一个序数，区别在于存在字段值相等的记录时，`RANK()` 会返回相同的序数；
- `COUNT()`, `SUM(col)`, `MIN(col)` 和一般的聚合操作相同。

### 3.窗口查询实现细节

简单来说，窗口查询有两个步骤：

* 将记录分割成多个分区;
* 然后在各个分区上调用窗口函数。

分区过程对于了解 MapReduce 的用户应该很容易理解，Hadoop 会负责对记录进行打散和排序。但是，传统的 UDAF 函数只能为每个分区返回一条记录，而我们需要的是不仅输入数据是一张表，输出数据也是一张表（table-in, table-out），因此 Hive 社区引入了分区表函数（PTF）。

PTF 顾名思义是运行于分区之上、能够处理分区中的记录并输出多行结果的函数。下方的时序图列出了这个过程中重要的一些类。`PTFOperator` 会读取已经排好序的数据，创建相应的“输入分区”；`WindowTableFunction` 则负责管理窗口帧、调用窗口函数（UDAF）、并将结果写入“输出分区”。

![PTF 时序图](../assets/window-sequence.png)

我们以具体的案例来分析一下窗口函数的map、reduce执行过程：

```sql
SELECT 
	a
	, RANK() OVER(partition by b order by c) as d 
from xyz; 
```

`RANK()` ：为数据集中的每个分区中的每一行分配一个序号。

`PARTITION BY` ：分区字段决定如何划分每一行数据。

`ORDER BY` ：决定了每个分区内的排序方式。

第一阶段是数据划分：数据集中的每一行数据都会被划分到指定的分区内。在mapreduce框架中，在map阶段，每一行数据根据partition by指定的字段进行分区，并按照order by指定的字段排序，每个分区内的数据有序。

第二阶段：map阶段结束之后，每个分区内的所有行都是有序的。在reduce阶段，每个reducer从指定的分区拉取数据，并将拉取到属于同一个分区的数据排序，排序键：order by指定的字段。

第三阶段：rank函数给一个分区内的每一行赋值一个有序。对于每一个分区的行，rank函数都会重新进行初始化。

对于rank函数来说，生成的有序序号是从1开始的。如果下一行与当前行值相同，则序号相同，否则rank = 当前行数。注意：如果排序列存在相同的值，那么生成的有序序列将不连续。

```sql
-- 根据b进行分组，并按照c进行排序
SELECT a, RANK() OVER(partition by b order by c) as d from xyz; 

a, b, c, d(rank)
----------------
1  1  1  1 -- starts with 1
2  1  1  1 -- the same c value, the same rank=1
3  1  2  3 -- note : rank 2 is skipped because second row shares the same rank as first 

4  2  3  1 --New partition starts with 1
5  2  4  2
6  2  5  3
```

而如果，我们想生成的是连续的序号，则可以使用ROW_NUMBER()函数：

```sql
SELECT a, ROW_NUMBER() OVER(partition by b order by c) as d from xyz; 

a, b, c, d(row_number)
----------------
1  1  1  1 --starts with 1
2  1  1  2 --the same c value, row number=2
3  1  2  3 --row position=3

4  2  3  1 --New partition starts with 1
5  2  4  2
6  2  5  3
```

此外，还有一个排序函数dense_rank()，

```sql
-- 根据b进行分组，并按照c进行排序
SELECT a, RANK() OVER(partition by b order by c) as d from xyz; 

a, b, c, d(rank)
----------------
1  1  1  1 -- starts with 1
2  1  1  1 -- the same c value, the same rank=1
3  1  2  2 -- num is consecutive

4  2  3  1 --New partition starts with 1
5  2  4  2
6  2  5  3
```



不同分区可以在多个reducer上并行处理，不同的分区数据互相不影响。

rown_number()函数源码实现核心逻辑：

```java
/**
   * 临时聚合结果：RowNumberBuffer
   */
static class RowNumberBuffer implements AggregationBuffer {
    ArrayList<IntWritable> rowNums;	// 存储分区中每行数据的序号
    int nextRow;
    boolean supportsStreaming;

    /**
     * row_number初始化，1
     * 针对不同分区，都会进行初始化操作
     */
    void init() {
        rowNums = new ArrayList<IntWritable>();
        nextRow = 1;
        if (supportsStreaming) {
            rowNums.add(null);
        }
    }

    RowNumberBuffer(boolean supportsStreaming) {
        this.supportsStreaming = supportsStreaming;
        init();
    }

    /**
     *  每次将计数器加一并放到list中
     */
    void incr() {
        if (supportsStreaming) {
            rowNums.set(0,new IntWritable(nextRow++));
        } else {
            rowNums.add(new IntWritable(nextRow++));
        }
    }
}
```



[Hive Window and Analytical Functions](http://shzhangji.com/blog/2017/09/04/hive-window-and-analytical-functions/)

[SQL Window function vs Group by](https://sundaskhalid.medium.com/sql-window-function-vs-group-by-b246d14223d2)

[Windowing function in Hive](https://stackoverflow.com/questions/55909029/windowing-function-in-hive)