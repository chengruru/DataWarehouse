# 1、设置map个数

mapreduce中没有办法直接控制map数量。通常情况下，作业会通过input的目录产生一个或者多个map任务。而map数量的主要决定因素有：

* input的文件总个数
* input的文件大小，集群设置的文件块大小(目前为128M, 可在hive中通过set dfs.block.size;命令查看到，该参数不能自定义修改)；

所以，改变map的个数，只能通过改变切片大小或者合并小文件的方式进行调整。举例来说，

* 假设input目录下有1个文件a,大小为800M,那么hadoop会将该文件a分隔成7个块（6个128m的块和1个32m的块），从而产生7个map数。
* 假设input目录下有3个文件a,b,c,大小分别为10m，20m，130m，那么hadoop会分隔成4个块（10m,20m,128m,2m），从而产生4个map数，即如果文件大于块大小(128m)，那么会拆分，如果小于块大小，则把该文件当成一个块。

如果要实现map中的数据合并需要设置下面的参数：

```shell
# 集群默认就是这个格式
set hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat;
```



## 1.1 设置多少个map合适？

map数普遍是通过执行时长来确认的，至少应当保证每个map执行时长在1分钟以上，太短的话意味着大量重复的jvm启用和销毁。具体设置要根据具体任务来处理，有些任务占用cpu大，有些占用io大。

## 1.2 设置map参数的影响？

设置map的话，影响不是很大，可能会带来更多的集群之间的io，毕竟要跨节点进行文件合并。

## 1.3 控制map数量的三个参数的逻辑概念

map任务可以简单的理解为：集群将一个表分区下面的文件分发到各个节点，之后根据mapred.max.split.size确认要启动多少个map数。

## 1.4 是不是map数越多越好？

答案是否定的。如果一个任务有很多小文件（远远小于块大小128m），则每个小文件也会被当做一个块，用一个map任务来完成，而一个map任务启动和初始化的时间远远大于逻辑处理的时间，就会造成很大的资源浪费。而且，同时可执行的map数是受限的。

## 1.5 是不是保证每个map处理接近128m的文件块，就可以了？

答案也是不一定。比如有一个128m的文件，正常会用一个map去完成，但这个文件只有一个或者两个小字段，却有几千万的记录，如果map处理的逻辑比较复杂，用一个map任务去做，肯定也比较耗时。

当任务逻辑复杂，map执行非常慢的时候，可以考虑增加Map数，来使得每个map处理的数据量减少，从而提高任务的执行效率。

## 1.6 合并小文件，减少map数参数配置

**（1）map输入时合并小文件**

```shell
# 1.执行Map前进行小文件合并
set hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat; 
# 2.每个Map最大输入大小，单位为KB
set mapred.max.split.size=128000000;  
# 3.一个节点上split的至少的大小，单位为KB
set mapred.min.split.size.per.node=100000000; 
# 4.一个交换机下split的至少的大小，单位为KB
set mapred.min.split.size.per.rack=100000000; 
```

**（2）map输出时合并小文件**

```shell
# 1.在Map-only的任务结束时合并小文件
set hive.merge.mapfiles=true;
# 2.在Map-Reduce的任务结束时合并小文件
set hive.merge.mapredfiles=true;
# 3.在hive on spark任务后开启合并小文件
set hive.merge.sparkfiles=true;
# 4.合并文件的大小
set hive.merge.size.per.task=256*1000*1000;
# 5.当输出文件的平均大小小于该值时，启动一个独立的map-reduce任务进行文件merge
set hive.merge.smallfiles.avgsize=16000000;
```

# 2、设置Reduce数量

reduce个数的设定极大影响任务的执行效率，不指定reduce个数的情况下，hive会基于以下两个参数计算reduce的个数(在hadoop中默认reduce只有一个的情况下，否则会对每个reduce都进行这种计算)

* hive.exec.reducers.bytes.per.reducer，如果reduce数据大小不大于这个值，则只有1个reduce，否则会有：数据量/hive.exec.reducers.bytes.per.reducer个reduce
* hive.exec.reducers.max，总的reduce数量不会超过这个值

## 2.1 调整reduce数量的方法

设置hive.exec.reducers.bytes.per.reducer的大小，在hadoop的mapred-default.xml中设置reduce的个数或通过hive shell设置，来硬性规定reduce的个数：

```shell
set mapreduce.job.reduces=reduceNum;
```

## 2.2 是不是reduce数量越多越好？

1. 过多的启动和初始化reduce也会消耗时间和资源；
2. 有多少个reduce就会有多少个输出文件，如果生成了很多小文件，如果这些小文件作为下一个任务的输入，则也会出现效率问题。

## 2.3  什么情况下只有一个reduce？

共有三种情况会导致这种结果：这三种情况都是全局的，hadoop不得不使用一个reduce来完成

1. 没有使用groupby这类汇总
2. 使用了order by
3. 有笛卡尔积

在设置reduce个数的时候也需要考虑这两个原则：

* 使大数据量利用合适的reduce数；
* 使单个reduce任务处理合适的数据量；



参考链接：

[hive中map/reduce数量的问题](https://blog.csdn.net/may_fly/article/details/102888436)







