# 并行执行

有时候reduce任务在map任务没有100%完成的时候就已经开始执行了，而reduce依赖map输出的数据。这样数据岂不是就不对了。

Hive 会将一个查询转化成一个或者多个阶段。这样的阶段可以是 MapReduce 阶段、抽样阶段、合并阶段、limit 阶段。或者 Hive 执行过程中可能需要的其他阶段。默认情况下，Hive 一次只会执行一个阶段。不过，某个特定的 job 可能包含众多的阶段，而这些阶段可能 并非完全互相依赖的，也就是说有些阶段是可以并行执行的，这样可能使得整个job的执行时间缩短。不过，如果有更多的阶段可以并行执行，那么job可能就越快完成。

通过设置参数 hive.exec.parallel 值为 true，就可以开启并发执行。不过，在共享集群中， 需要注意下，如果 job 中并行阶段增多，那么集群利用率就会增加。

```shell
# 1.打开任务并行执行
set hive.exec.parallel=true; 
# 2.同一个 sql 允许最大并行度，默认为8
set hive.exec.parallel.thread.number=16; 
```

当然，得是在系统资源比较空闲的时候才有优势，否则，没资源，并行也起不来。